# DIMOS Framework Documentation

Welcome to the DIMOS (Dimensional OS) framework documentation. This guide will help you understand, extend, and integrate DIMOS into your robotics projects.

## ğŸ“š Documentation Structure

### ğŸš€ Getting Started
- [Main README](../README.md) - Quick start and basic setup
- [Installation Guide](../README.md#python-quick-start-) - Detailed installation instructions

### ğŸ“– Guides

#### Core Integration (Start Here)
- **[Agent-to-Robot Integration](guides/integration.md)** - Complete pipeline from natural language to robot actions
- **[Skills Extension](guides/skills.md)** - Creating custom skills and extending robot capabilities
- **[Observable Streams](guides/observables.md)** - RxPY patterns and data flow in DIMOS

#### Advanced Features
- **[Semantic Memory & RAG](guides/memory.md)** - Spatial reasoning and retrieval-augmented generation
- **[Perception & Vision](guides/perception.md)** - Vision pipelines, VLM integration, object detection
- **[Robot Platform Abstraction](guides/robot-platforms.md)** - Adapting DIMOS to new robot platforms

### ğŸ“‘ API Reference
- **[Agents API](api/agents.md)** - OpenAIAgent, PlanningAgent, ClaudeAgent, and base classes
- **[Skills API](api/skills.md)** - AbstractSkill, AbstractRobotSkill, SkillLibrary
- **[Robot API](api/robot.md)** - Robot base class and platform implementations

### ğŸ“ Tutorials
- **[Basic Agent Setup](tutorials/basic-agent.md)** - Your first DIMOS agent
- **[Custom Skill Development](tutorials/custom-skill.md)** - Step-by-step skill creation
- **[Multi-Agent Orchestration](tutorials/multi-agent.md)** - Chaining agents for complex tasks

## ğŸ¯ Quick Navigation by Use Case

### I want to...

**Build a basic robot agent**
1. Read [Agent-to-Robot Integration](guides/integration.md)
2. Follow [Basic Agent Setup](tutorials/basic-agent.md)
3. Reference [Agents API](api/agents.md)

**Create custom robot behaviors**
1. Read [Skills Extension](guides/skills.md)
2. Follow [Custom Skill Development](tutorials/custom-skill.md)
3. Reference [Skills API](api/skills.md)

**Add vision capabilities**
1. Read [Perception & Vision](guides/perception.md)
2. Reference [Agents API](api/agents.md) for vision-enabled agents

**Implement spatial memory**
1. Read [Semantic Memory & RAG](guides/memory.md)
2. Reference [Agents API](api/agents.md) for memory configuration

**Port DIMOS to a new robot**
1. Read [Robot Platform Abstraction](guides/robot-platforms.md)
2. Reference [Robot API](api/robot.md)

**Understand data flow**
1. Read [Observable Streams](guides/observables.md)
2. Read [Agent-to-Robot Integration](guides/integration.md)

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interface                           â”‚
â”‚                   (Web UI / CLI / Voice)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Observable<str> (queries)
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Agent Layer                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Planning    â”‚â”€â–¶â”‚ Execution    â”‚  â”‚ Semantic Memory â”‚        â”‚
â”‚  â”‚ Agent       â”‚  â”‚ Agent        â”‚  â”‚ (ChromaDB)      â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Tool Calls (Skills)
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Skills Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Move     â”‚  â”‚ Navigate â”‚  â”‚ Detect   â”‚  â”‚ Custom   â”‚       â”‚
â”‚  â”‚ Skills   â”‚  â”‚ Skills   â”‚  â”‚ Objects  â”‚  â”‚ Skills   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Robot Interface Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ ROS2 Control     â”‚         â”‚ WebRTC API       â”‚             â”‚
â”‚  â”‚ (velocity, pose) â”‚         â”‚ (behaviors)      â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                               â”‚
            â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Physical Robot                              â”‚
â”‚               (Unitree Go2, Custom Robot, etc.)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ Feedback (state, video, sensors)
            â–¼
    Observable Streams (RxPY)
```

## ğŸ”‘ Key Concepts

### Agents
Agents are LLM-powered decision-makers that process inputs, reason about goals, and invoke skills to achieve objectives. DIMOS supports multiple agent types (OpenAI, Claude, local models) and agent chaining.

### Skills
Skills are discrete robot capabilities (move, navigate, detect objects, etc.) that agents can invoke via tool calling. Skills are Pydantic models with validation and execution logic.

### Observable Streams
DIMOS uses RxPY for reactive programming, allowing asynchronous data flow between components (video frames, commands, state updates).

### Semantic Memory
ChromaDB-backed vector storage enables agents to store and retrieve spatially-grounded observations for context-aware reasoning.

## ğŸ“¦ Project Structure Reference

```
dimos/
â”œâ”€â”€ agents/           # Agent implementations and memory systems
â”‚   â”œâ”€â”€ agent.py      # OpenAIAgent, LLMAgent base classes
â”‚   â”œâ”€â”€ planning_agent.py
â”‚   â”œâ”€â”€ claude_agent.py
â”‚   â””â”€â”€ memory/       # Semantic memory implementations
â”‚       â”œâ”€â”€ base.py
â”‚       â””â”€â”€ chroma_impl.py
â”œâ”€â”€ robot/            # Robot abstraction and platform implementations
â”‚   â”œâ”€â”€ robot.py      # Robot base class
â”‚   â”œâ”€â”€ ros_control.py
â”‚   â””â”€â”€ unitree/      # Unitree Go2 specific implementations
â”œâ”€â”€ skills/           # Skill definitions and library
â”‚   â”œâ”€â”€ skills.py     # AbstractSkill, SkillLibrary
â”‚   â”œâ”€â”€ navigation.py
â”‚   â””â”€â”€ observe_stream.py
â”œâ”€â”€ perception/       # Computer vision and sensing
â”‚   â”œâ”€â”€ detection2d/
â”‚   â”œâ”€â”€ spatial_perception.py
â”‚   â””â”€â”€ object_detection_stream.py
â”œâ”€â”€ stream/           # Video and data streaming utilities
â”‚   â”œâ”€â”€ frame_processor.py
â”‚   â””â”€â”€ video_providers/
â””â”€â”€ web/              # Web interface and API
    â””â”€â”€ dimos_interface/
```

## ğŸ¤ Contributing

We welcome contributions to the documentation! If you find errors, have suggestions, or want to add examples:

1. Fork the repository
2. Create a documentation branch
3. Submit a pull request with your improvements

## ğŸ“ Support

- **GitHub Issues**: [Report bugs or request features](https://github.com/dimensionalOS/dimos-unitree/issues)
- **Email**: build@dimensionalOS.com
- **Community**: Join the [Roboverse Discord](https://discord.gg/HEXNMCNhEh)

## ğŸ“„ License

DIMOS is licensed under the Apache 2.0 License. See [LICENSE](../LICENSE) for details.

---

**Next Steps**: Start with the [Agent-to-Robot Integration Guide](guides/integration.md) to understand the complete pipeline from natural language to robot actions.
